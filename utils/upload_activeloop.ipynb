{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import deeplake\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def is_code_file(filename):\n",
    "    # Add file extensions of the code files you want to process\n",
    "    code_file_extensions = ['.sol']\n",
    "    return any(filename.endswith(ext) for ext in code_file_extensions)\n",
    "\n",
    "\n",
    "def remove_comments(text):\n",
    "    # Remove single-line and multi-line comments\n",
    "    # Adjust the regex according to the language of the code files\n",
    "    single_line_comment = r'\\/\\/[^\\n]*'\n",
    "    multi_line_comment = r'\\/\\*[\\s\\S]*?\\*\\/'\n",
    "    return re.sub(f\"{single_line_comment}|{multi_line_comment}\", \"\", text)\n",
    "\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "def remove_string_literals(text):\n",
    "    single_quoted_string = r\"'([^'\\\\]|\\\\.)*'\"\n",
    "    double_quoted_string = r'\"([^\"\\\\]|\\\\.)*\"'\n",
    "    return re.sub(f\"{single_quoted_string}|{double_quoted_string}\", \"\", text)\n",
    "\n",
    "\n",
    "def create_and_index_deeplake_dataset(embeddings, deeplake_path, root_dir):\n",
    "    docs = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    db = DeepLake.from_documents(texts, embeddings, dataset_path=deeplake_path)\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "# Usage example\n",
    "embeddings = OpenAIEmbeddings()\n",
    "deeplake_path = 'hub://kevinpark/ds1'\n",
    "# root_dir = './clone-nayms'\n",
    "# root_dir = './clone-nayms/test/'\n",
    "# root_dir = './clone-nayms/src/diamonds/nayms/facets'\n",
    "root_dir = './clone-nayms/src/erc20'\n",
    "\n",
    "db = create_and_index_deeplake_dataset(embeddings, deeplake_path, root_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
